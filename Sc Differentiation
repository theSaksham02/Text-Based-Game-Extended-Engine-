# Importing the necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import json

# Constants
IMG_WIDTH = 128
IMG_HEIGHT = 128
BATCH_SIZE = 32
EPOCHS = 30
# 
# Data preprocessing configuration
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    brightness_range=[0.8, 1.2],
    validation_split=0.2,
)

validation_datagen = ImageDataGenerator(rescale=1.0/255)

# Utility functions
def load_and_preprocess_image(image_path):
    try:
        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(IMG_WIDTH, IMG_HEIGHT))
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0) / 255.0
        return img_array
    except Exception as e:
        print(f"Error loading image {image_path}: {str(e)}")
        return None

def create_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

def train_model(model, train_data, validation_data):
    early_stopping = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    )
    
    checkpoint = tf.keras.callbacks.ModelCheckpoint(
        "best_model.h5",
        monitor='val_loss',
        save_best_only=True
    )
    
    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=3,
        min_lr=0.00001
    )
    
    history = model.fit(
        train_data,
        steps_per_epoch=train_data.samples // BATCH_SIZE,
        validation_data=validation_data,
        validation_steps=validation_data.samples // BATCH_SIZE,
        epochs=EPOCHS,
        callbacks=[early_stopping, checkpoint, reduce_lr]
    )
    return history

def evaluate_model(model, test_data):
    try:
        loss, accuracy = model.evaluate(test_data)
        print(f"Test Accuracy: {accuracy * 100:.2f}%")
        print(f"Test Loss: {loss:.4f}")
        return loss, accuracy
    except Exception as e:
        print(f"Error evaluating model: {str(e)}")
        return None, None

def visualize_predictions(model, data_dir, num_images=5):
    try:
        datagen = ImageDataGenerator(rescale=1.0/255)
        generator = datagen.flow_from_directory(
            data_dir,
            target_size=(IMG_WIDTH, IMG_HEIGHT),
            batch_size=1,
            class_mode="binary",
            shuffle=True
        )
        
        plt.figure(figsize=(15, 5))
        for i in range(num_images):
            img, label = next(generator)
            prediction = model.predict(img)
            plt.subplot(1, num_images, i + 1)
            plt.imshow(img[0])
            plt.title(f"Pred: {'Differentiated' if prediction[0] > 0.5 else 'Undifferentiated'}\nTrue: {'Differentiated' if label[0] > 0.5 else 'Undifferentiated'}")
            plt.axis('off')
        plt.show()
    except Exception as e:
        print(f"Error visualizing predictions: {str(e)}")

def save_model_predictions(model, data_dir, output_file="predictions.csv"):
    try:
        datagen = ImageDataGenerator(rescale=1.0/255)
        generator = datagen.flow_from_directory(
            data_dir,
            target_size=(IMG_WIDTH, IMG_HEIGHT),
            batch_size=1,
            class_mode="binary",
            shuffle=False
        )
        
        predictions = model.predict(generator)
        predicted_classes = np.where(predictions > 0.5, 1, 0)
        
        with open(output_file, "w") as f:
            f.write("Filename,Predicted Class\n")
            for i, filename in enumerate(generator.filenames):
                f.write(f"{filename},{'Differentiated' if predicted_classes[i] == 1 else 'Undifferentiated'}\n")
        print(f"Predictions saved to {output_file}")
    except Exception as e:
        print(f"Error saving predictions: {str(e)}")

# Main execution
if __name__ == "__main__":
    # Create and compile model
    model = create_model()
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    # Load data
    train_data = train_datagen.flow_from_directory(
        "train",
        target_size=(IMG_WIDTH, IMG_HEIGHT),
        batch_size=BATCH_SIZE,
        class_mode='binary',
        subset='training'
    )
    
    validation_data = validation_datagen.flow_from_directory(
        "validation",
        target_size=(IMG_WIDTH, IMG_HEIGHT),
        batch_size=BATCH_SIZE,
        class_mode='binary',
        subset='validation'
    )
    
    # Train model
    history = train_model(model, train_data, validation_data)
    
    # Evaluate model
    evaluate_model(model, validation_data)
    
    # Visualize predictions
    visualize_predictions(model, "test")
    
    # Save predictions
    save_model_predictions(model, "test")
    
    # Save final model
    model.save("final_model.h5")
    print("Model saved successfully.")